{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a961245d-b652-47a7-b1e5-53e76f21a382",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933c79d5-562a-468e-9ba6-d4fb6b7ca452",
   "metadata": {},
   "source": [
    "# Load Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9de6a44-e171-48ae-940c-3da7b5f32360",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('artifacts/embeddings_inputs.pkl', 'rb') as f:\n",
    "    loaded_input_items = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6967b734-1889-4dfe-8d02-f795f15a2435",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pad = loaded_input_items['X_train_pad']\n",
    "X_val_pad = loaded_input_items['X_val_pad']\n",
    "X_test_pad = loaded_input_items['X_test_pad']\n",
    "y_train = loaded_input_items['y_train']\n",
    "y_val = loaded_input_items['y_val']\n",
    "y_test = loaded_input_items['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3418a202-1973-4c02-b3d8-738d4292bb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = len(X_train_pad[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7015e775-d545-40d6-a256-b0ab19e9c4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('artifacts/tokenizer.pkl', 'rb') as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "VOCAB_SIZE = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bad648c2-b0cf-4ebf-b37c-d2e798bd2359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum input length: 588, Vocab size: 35756\n"
     ]
    }
   ],
   "source": [
    "print(f\"Maximum input length: {MAX_LEN}, Vocab size: {VOCAB_SIZE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857d40c1-b7f9-4ab5-9ac4-311c9d4b8dd7",
   "metadata": {},
   "source": [
    "# Load GloVe Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "967f4b2a-db50-4f5d-8d85-d755dfc142f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOVE_PATH = r\"C:\\Users\\aleen\\glove\\glove_2024_wikigiga_100d.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e5774d0-33b7-4381-ac79-cac4e3ca2512",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5278b1-306e-4b13-8400-f0b6de8fa3de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embedding_index = {}\n",
    "with open(GLOVE_PATH, encoding='utf-8') as f:\n",
    "    c=0\n",
    "    for line in f:\n",
    "        values = line.strip().split()\n",
    "        c+=1\n",
    "        word = values[0]\n",
    "        try:\n",
    "            vector = np.array([float(value) for value in values[1:]])\n",
    "            embedding_index[word] = vector \n",
    "        except:\n",
    "            print(\"ERROR!\")\n",
    "            print(word, values)\n",
    "print(f\"Loaded {len(embedding_index)} word vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13bf2c7f-b04f-4d53-83b2-d9e1ddcd38af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1287623 word vectors\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loaded {len(embedding_index)} word vectors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6191239a-9196-4a4b-8b0a-02ae9424b8d3",
   "metadata": {},
   "source": [
    "# Building Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bef618ad-43e2-469a-926a-b958c3040a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.434792,  0.498616,  0.17971 ,  0.704012,  0.517303,  0.441844,\n",
       "       -0.891324, -0.092814, -0.934273,  0.32357 ,  0.324631, -0.33741 ,\n",
       "       -0.678446, -0.680584,  0.458958, -0.06935 , -0.131736,  0.011698,\n",
       "       -0.381304, -0.759487, -0.47045 ,  0.019226, -0.908428, -0.281665,\n",
       "        0.195382, -0.185935, -0.068366, -0.889806, -0.140643,  0.359133,\n",
       "       -0.618384,  0.072123, -0.369979,  0.402194, -5.404896,  0.251164,\n",
       "        0.402286,  0.22511 ,  0.479287, -0.515167,  0.132093, -0.226698,\n",
       "        0.704942, -0.145151,  0.708178,  0.698086, -0.199204, -0.164803,\n",
       "        2.366336,  0.769954, -0.579768, -1.424587,  0.102187,  0.061161,\n",
       "        0.006214,  0.958536,  0.884203,  0.543308, -0.018456, -0.401535,\n",
       "        0.129765, -0.34603 ,  0.360544,  0.619073, -0.609613,  0.208515,\n",
       "        0.300205,  0.1291  , -0.160847,  0.778184,  0.151817,  0.80319 ,\n",
       "        1.010414, -0.640239, -0.247022,  0.443756, -0.094733, -0.374166,\n",
       "        0.076299, -0.152046, -0.092171,  0.61828 ,  0.08652 , -0.398011,\n",
       "        0.971293, -0.47263 ,  0.262463, -0.737917, -0.472104, -0.541116,\n",
       "        0.771661, -0.433793,  0.057226,  0.197278, -0.556113, -1.14942 ,\n",
       "       -0.443387,  0.07095 , -0.546782,  0.690232])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_index['said']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9aa6012c-637f-4736-8a30-a3afc6224837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1252158\n"
     ]
    }
   ],
   "source": [
    "print(len([t for t in embedding_index if t not in tokenizer.word_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97536a02-63dc-4c5a-a109-4eadb34ddfc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290\n"
     ]
    }
   ],
   "source": [
    "print(len([t for t in tokenizer.word_index if t not in embedding_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19984709-7326-48e5-8058-277435bc8165",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "known_indices = []\n",
    "embedding_matrix = np.zeros((VOCAB_SIZE, EMBEDDING_DIM))\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    if word in embedding_index and embedding_index.get(word) is not None:\n",
    "        c += 1\n",
    "        known_indices.append(index)\n",
    "        embedding_matrix[index] = embedding_index[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "605598df-85ba-400f-88e2-2c8feb6f928d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.        0.        0.        0.        0.        0.        0.\n",
      "   0.        0.        0.        0.        0.        0.        0.\n",
      "   0.        0.        0.        0.        0.        0.        0.\n",
      "   0.        0.        0.        0.        0.        0.        0.\n",
      "   0.        0.        0.        0.        0.        0.        0.\n",
      "   0.        0.        0.        0.        0.        0.        0.\n",
      "   0.        0.        0.        0.        0.        0.        0.\n",
      "   0.        0.        0.        0.        0.        0.        0.\n",
      "   0.        0.        0.        0.        0.        0.        0.\n",
      "   0.        0.        0.        0.        0.        0.        0.\n",
      "   0.        0.        0.        0.        0.        0.        0.\n",
      "   0.        0.        0.        0.        0.        0.        0.\n",
      "   0.        0.        0.        0.        0.        0.        0.\n",
      "   0.        0.        0.        0.        0.        0.        0.\n",
      "   0.        0.      ]\n",
      " [ 0.411022  0.478867 -0.705308  1.087929  0.247115 -0.176871  0.121813\n",
      "  -0.056681 -0.059729  0.777992  0.618769  0.137911 -0.0743   -0.810912\n",
      "  -0.082164 -0.574812 -0.149253 -0.488883  0.302537  0.398955 -0.022197\n",
      "  -0.398771  0.046215  0.08288  -0.637958  0.279833  0.119709 -0.043359\n",
      "   0.498382  0.921615 -0.348264 -0.015964  0.575408  0.359311 -1.011766\n",
      "  -0.511347  0.081244  0.913249  0.5876    0.449356  0.158405 -0.189166\n",
      "  -0.569937  0.378416 -0.197093  0.406646  0.129058  0.225685  0.550846\n",
      "  -0.826382 -0.050294  0.916583  0.27042  -0.074964 -0.036588 -0.891906\n",
      "   0.801019  0.66327  -0.635988  0.574883 -0.383964  0.485573 -0.227331\n",
      "  -0.330436  0.016323 -0.092953 -0.449168 -1.214263  0.007786  0.169781\n",
      "  -0.820273 -0.077729 -0.299304 -0.343714 -0.161444  0.084816  0.115211\n",
      "   0.728542 -0.06768   0.421187 -0.057051 -0.692954 -0.084839 -0.244558\n",
      "  -0.044246  0.17966   0.17885   0.623131  0.055732  0.369891  0.19593\n",
      "   0.219583 -0.609889 -0.186998  0.157425  0.682104  0.391498 -0.024427\n",
      "   0.234402 -0.43416 ]\n",
      " [ 0.655745  0.240574 -0.928703 -0.129289  0.134887 -0.434267  0.133422\n",
      "  -0.021425 -0.294573  0.677294  0.969649 -0.459664 -0.096329 -0.540574\n",
      "   0.519448  0.402777  0.49719  -0.192362  0.633895  0.092422 -0.566309\n",
      "   0.800332  0.458442 -0.738388 -0.380563 -0.102771 -0.09728  -0.105148\n",
      "  -0.228191 -0.55663  -0.203912  0.426302  0.551992 -0.337441  0.28387\n",
      "   0.174202  0.200916  0.497861  0.240047  0.174118 -0.425877 -0.583783\n",
      "   0.119754  0.909337  0.046497  0.777438 -0.288287 -0.371628 -0.390071\n",
      "  -0.667513 -0.159998 -0.410833  0.46477  -0.431355 -0.245311 -0.802759\n",
      "  -0.040911  0.505172 -0.848467  0.853344 -0.564883 -0.379333  0.162895\n",
      "  -0.379745 -0.569688 -0.682673  0.351997 -0.458116  0.272968  0.297842\n",
      "  -0.22184   0.026898  0.105994  0.029094  0.456152 -0.150134  0.08943\n",
      "  -0.387521  0.204691  0.353638 -0.129743 -0.239001  0.474323  0.490516\n",
      "   0.129618 -0.160734  0.785287  0.196791 -0.012708  0.722934  0.162133\n",
      "  -0.028191 -0.215554  0.021654 -0.222539  0.46481  -0.244667 -0.603557\n",
      "   0.244552 -0.677834]\n",
      " [ 0.247531 -0.867118  0.435672 -0.460347  0.052394 -0.060986  0.44912\n",
      "  -0.21199  -0.359113  0.568617  0.319641  0.18396  -0.384901  0.001813\n",
      "   0.451025  0.680635  0.565778  0.227335 -0.516773 -0.367504  0.330756\n",
      "  -1.296856 -1.336551 -0.696922  0.373303 -0.381605 -0.63431   0.011208\n",
      "  -0.412105 -0.356174 -0.3713    0.102601 -0.532272 -0.421111 -0.193107\n",
      "   0.116759 -0.654256 -0.354452  0.031896 -0.292037  0.053354  0.150029\n",
      "   0.167638  0.560505 -0.360143  0.826331  0.32161   0.015325  0.312666\n",
      "  -0.649191  0.191038 -0.786513  0.977152  0.232747  0.025891  0.59923\n",
      "   0.097285  0.206114 -0.019421 -0.570233  0.390053  0.409272 -0.491107\n",
      "   0.143482 -0.12819  -0.58603   0.752509  0.142441 -0.408    -0.216528\n",
      "  -0.219199  0.310324  0.20235   0.035097 -0.055981  0.041305  0.386826\n",
      "  -0.397791  0.188752  0.041914 -0.268281 -0.698444 -0.526528 -0.042091\n",
      "   0.038764 -0.817471  0.326134  0.384923  0.171953 -0.016984  0.045724\n",
      "   0.92796  -0.052197  0.761522 -0.822977  0.244547  0.056334 -0.034886\n",
      "   0.727875  0.441182]]\n"
     ]
    }
   ],
   "source": [
    "print(embedding_matrix[::10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e217070-7275-4e11-b851-4d14bcaf7750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291 0.8138494238729165\n"
     ]
    }
   ],
   "source": [
    "print(VOCAB_SIZE-c, (float(VOCAB_SIZE-c)/VOCAB_SIZE)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c085b0cf-38ac-4eee-b3e9-466d2dd108e3",
   "metadata": {},
   "source": [
    "* The embeddings for **oov token** and **290** other tokens are missing, these can be left as 0s, be give random values, or be computed by averaging the embeddings of all other known tokens. **<1%** of the tokens' embeddings are only missing, so, that is not much of an issue.\n",
    "\n",
    "* Regardless, we will set `trainable=True` in the Embedding layer of classifiers, so that the embeddings of missing tokens will be learnt during the model training. Allowing all the embeddings to be trained will also help in fine-tuning them, because since these were pre-trained they may not be entirely aligned with the context of our dataset/task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430fde3e-9cce-4934-b610-097d05d4fec2",
   "metadata": {},
   "source": [
    "# Saving the Pretrained Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9797e296-ee39-46fb-93f8-a35c252a8777",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_input = {\n",
    "    'embedding_matrix': embedding_matrix,\n",
    "    'X_train_pad': X_train_pad,\n",
    "    'X_val_pad': X_val_pad,\n",
    "    'X_test_pad': X_test_pad,\n",
    "    'y_train': y_train,\n",
    "    'y_val': y_val,\n",
    "    'y_test': y_test\n",
    "}\n",
    "with open('artifacts/pretrained_embeddings_inputs.pkl', 'wb') as f:\n",
    "    pickle.dump(embeddings_input, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
